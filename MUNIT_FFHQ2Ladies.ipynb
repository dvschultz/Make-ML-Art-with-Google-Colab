{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUNIT-FFHQ2Ladies.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/Make-ML-Art-with-Google-Colab/blob/master/MUNIT_FFHQ2Ladies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdC23munnMbJ",
        "colab_type": "text"
      },
      "source": [
        "#MUNIT\n",
        "MUNIT stands for Multimodal UNsupervised Image-to-image Translation. That’s a lot of words to say it can convert images of cats to images of dogs, or images of horses to images of zebras. Basically, it learns to convert one set of images (a “domain”) to another set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-bEjUkJjPAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "3fac67f0-cffa-4e13-ce36-7a61ac3c87b1"
      },
      "source": [
        "#only run once!\n",
        "!git clone https://github.com/dvschultz/MUNIT\n",
        "\n",
        "#install dependencies\n",
        "#!pip install torch torchvision tensorboard tensorboardX PyYAML torchfile\n",
        "!pip tensorboardX torchfile\n",
        "%cd MUNIT\n",
        "#make some folders\n",
        "%mkdir models\n",
        "%mkdir styles\n",
        "#install config file and checkpoints\n",
        "%cd configs\n",
        "!gdown --id 1GS-X6ByJCC9Ap4YzXdflFzcJPxjzGrnv\n",
        "%cd ../models/\n",
        "!gdown --id 1k2nFAiAV8yshRpZK14F0qlHgL1zDVYxG\n",
        "!mkdir ../datasets/ffhq2ladies/\n",
        "!mkdir ../datasets/ffhq2ladies/testA\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MUNIT'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 468 (delta 28), reused 0 (delta 0), pack-reused 418\u001b[K\n",
            "Receiving objects: 100% (468/468), 6.13 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (240/240), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: tensorboard in /tensorflow-1.15.0/python3.6 (1.15.0)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (46.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.24.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.1)\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=c34844e0af6a3e9676944dba76da5c2c898e4f75bc043c63961de3b10eb56b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built torchfile\n",
            "Installing collected packages: tensorboardX, torchfile\n",
            "Successfully installed tensorboardX-2.0 torchfile-0.1.0\n",
            "/content/MUNIT\n",
            "/content/MUNIT/configs\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GS-X6ByJCC9Ap4YzXdflFzcJPxjzGrnv\n",
            "To: /content/MUNIT/configs/config.yaml\n",
            "100% 3.17k/3.17k [00:00<00:00, 2.91MB/s]\n",
            "/content/MUNIT/models\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k2nFAiAV8yshRpZK14F0qlHgL1zDVYxG\n",
            "To: /content/MUNIT/models/gen_00390000.pt\n",
            "120MB [00:08, 14.6MB/s]\n",
            "/content/MUNIT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-trlecLYPJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "19ab28f9-ba66-461b-85b0-c0de1a4ddc6a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGaL9GJpRbWb",
        "colab_type": "text"
      },
      "source": [
        "##Testing Options\n",
        "\n",
        "`--num_style`\n",
        "How many \"styles\" you want to output\n",
        "\n",
        "`--num_style_start` What index to start with. If you combine this with `--num_style 1` you can generate only the style you want once determined (for example, run 500 samples, pick your favorite, then only ever test with that one.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFqnhW_eTUvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2c60a032-6248-4793-d13d-0643c50ac6e1"
      },
      "source": [
        "import os\n",
        "from random import randint\n",
        "\n",
        "def processFolder(folder, numStyles = 10):\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  for f in files:\n",
        "    print(f)\n",
        "    randInt = randint(0,1000)\n",
        "    os.system('python test.py --config /content/MUNIT/configs/config.yaml --input /content/MUNIT/datasets/ffhq2ladies/testA/%s --output_folder /content/drive/My\\ Drive/MUNIT_plantfaces/%s --checkpoint /content/MUNIT/models/gen_00390000.pt --a2b 1 --num_style %i --num_style_start %i' % (f, f, numStyles, randInt))\n",
        "\n",
        "processFolder('/content/MUNIT/datasets/ffhq2ladies/testA',25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "martin_eve_2020-Mar-25.png\n",
            "mel_tar_2020-Mar-25-02.jpg\n",
            "mel_tar_2020-Mar-25.jpg\n",
            "RouhiRoo_2020-Mar-25.jpg\n",
            "melissaterras_2020-Mar-25.jpg\n",
            "IMG_4272.PNG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsiVvLuFsGTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}